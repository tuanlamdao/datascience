{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "colab": {
      "name": "12 - Combining learners.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tuanlamdao/datascience/blob/master/12_Combining_learners.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "B9VTNK9hQto-"
      },
      "source": [
        "from tuanlam import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "clQgiObxQtpD"
      },
      "source": [
        "digits = datasets.load_digits()\n",
        "digits_ftrs, digits_tgt = digits.data, digits.target\n",
        "\n",
        "diabetes = datasets.load_diabetes()\n",
        "diabetes_ftrs, diabetes_tgt = diabetes.data, diabetes.target\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "tts = skms.train_test_split(iris.data, iris.target, test_size=.75, stratify=iris.target)\n",
        "\n",
        "(iris_train_ftrs, iris_test_ftrs, iris_train_tgt, iris_test_tgt) = tts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yfx6W_VGQtpG"
      },
      "source": [
        "#### Ensembles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FiNfqd2gQtpH",
        "outputId": "8b3aac0c-ab64-47ce-cab9-71d8404111f5"
      },
      "source": [
        "base_estimators = [linear_model.LogisticRegression(), tree.DecisionTreeClassifier(max_depth=3), naive_bayes.GaussianNB()]\n",
        "base_estimators = [(get_model_name(m), m) for m in base_estimators]\n",
        "\n",
        "ensemble_model = ensemble.VotingClassifier(estimators = base_estimators)\n",
        "skms.cross_val_score(ensemble_model, digits_ftrs, digits_tgt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.8571, 0.8397, 0.8742])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpXSdJPtQtpK"
      },
      "source": [
        "- combining different types of models like a linear regression and a decision tree regressor is called stacking\n",
        "- combining models with different biases can result in a less biased aggregate model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM0HuvmmQtpK"
      },
      "source": [
        "##### Bagging and Random forests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHCcxB7YQtpL"
      },
      "source": [
        "##### Bootstraping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RPUByPmjQtpL",
        "outputId": "65968cc0-9af6-4ff5-8846-3926b58123f4"
      },
      "source": [
        "dataset = np.array([1,5,10,10,17,20,35])\n",
        "def compute_mean(data):\n",
        "    return np.sum(data) / data.size\n",
        "compute_mean(dataset)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5kX-ruCnQtpO",
        "outputId": "584459f0-47d7-4f4b-8b49-aae33c57d949"
      },
      "source": [
        "def bootstrap_sample(data):\n",
        "    N = len(data)\n",
        "    idx = np.arange(N)\n",
        "    bs_idx = np.random.choice(idx,N, replace=True)\n",
        "    return data[bs_idx]\n",
        "\n",
        "bsms = []\n",
        "for i in range(5):\n",
        "    bs_sample = bootstrap_sample(dataset)\n",
        "    bs_mean = compute_mean(bs_sample)\n",
        "    bsms.append(bs_mean)\n",
        "    print(bs_sample, \"{:5.2f}\".format(bs_mean))\n",
        "\n",
        "print(\"{:5.2f}\".format(sum(bsms)/len(bsms)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10 20 17 20 17 20 10] 16.29\n",
            "[10  1 17 17  1 20 17] 11.86\n",
            "[35 10 10  1 10 35 17] 16.86\n",
            "[17 35  1 10  5  1  5] 10.57\n",
            "[35 20  5 10 20  5 35] 18.57\n",
            "14.83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DteWVCSCQtpR",
        "outputId": "6fd588e4-84d3-4b01-b336-f5e4c1e96080"
      },
      "source": [
        "def compute_bootstrap_statistic(data, num_boots, statistic):\n",
        "    bs_stats = [statistic(bootstrap_sample(data)) for i in range(num_boots)]\n",
        "    return np.sum(bs_stats) / num_boots\n",
        "\n",
        "bs_mean = compute_bootstrap_statistic(dataset, 100, compute_mean)\n",
        "print(\"{:5.2f}\".format(bs_mean))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13.81\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dxAqX3EQtpV"
      },
      "source": [
        "##### From bootstrapping to bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "j0ZshD8eQtpV",
        "outputId": "46ea0320-d4e6-4728-bb3a-fb377e935269"
      },
      "source": [
        "def make_knn_statistic(new_example):\n",
        "    def knn_statistic(dataset):\n",
        "        ftrs, tgt = dataset[:,:-1], dataset[:,-1]\n",
        "        knn = neighbors.KNeighborsRegressor(n_neighbors=3).fit(ftrs,tgt)\n",
        "        return knn.predict(new_example)\n",
        "    return knn_statistic\n",
        "\n",
        "diabetes_dataset = np.c_[diabetes_ftrs, diabetes_tgt]\n",
        "ks = make_knn_statistic(diabetes_ftrs[-1].reshape(1,-1))\n",
        "compute_bootstrap_statistic(diabetes_dataset, 100, ks)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73.98333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNnyCztOQtpY"
      },
      "source": [
        "we can mimic that process and turn it in to our basic algorithm for bagging:\n",
        "1. sample the data with replacement\n",
        "2. create the model and train it on the data\n",
        "3. Repeat\n",
        "to predict, we feed an example into each of the trained models and combines their predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aYkI_05xQtpY"
      },
      "source": [
        "def bagged_learner(dataset, base_model, num_models=10):\n",
        "    models = []\n",
        "    for n in num_models:\n",
        "        bs_sample = np.random.choice(dataset, N, replace=True)\n",
        "        models.append(base_model().fit(*bs_sample))\n",
        "    return models\n",
        "\n",
        "def bagged_predict_class(models, example):\n",
        "    preds = [m.predict(example) for  m in models]\n",
        "    return pd.Series(preds).mode()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QA9EDec7Qtpc"
      },
      "source": [
        "##### Random forest \n",
        "it is a specific type of a bagged leaner built on top of decision trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gwt08ETOQtpc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}