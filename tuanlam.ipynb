{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tuanlam.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMmoHJaCarfW35wNHp9KSO/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tuanlamdao/datascience/blob/master/tuanlam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQ2iR5ac6-Jz"
      },
      "source": [
        "# common import abbreviations\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import patsy\n",
        "\n",
        "######################################################################################\n",
        "import itertools as it\n",
        "import collections as co\n",
        "import functools as ft\n",
        "import os.path as osp\n",
        "\n",
        "import glob\n",
        "import textwrap\n",
        "\n",
        "import os\n",
        "######################################################################################\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "#some warning are stubborn in the extrem, we don't want\n",
        "#them in our python program\n",
        "######################################################################################\n",
        "def warn(*args, **kwargs): pass\n",
        "warnings.warn = warn\n",
        "#config related\n",
        "np.set_printoptions(precision=4,\n",
        "                    suppress=True)\n",
        "pd.options.display.float_format = '{:20,.4f}'.format\n",
        "#there are good reasons not to do this in any real production code\n",
        "#for our purpose of simpler the problem, this is what we want\n",
        "np.random.seed(42)\n",
        "#default is [6.4, 4.8] (4:3)\n",
        "mpl.rcParams['figure.figsize'] = [4.0,3.0]\n",
        "#turn on latex tables\n",
        "pd.set_option('display.latex.repr', True)\n",
        "#monkey-patch for centering out[] DataFrames\n",
        "def _repr_latex_(self):\n",
        "    return \"{\\centering\\n%s\\n\\medskip}\" % sef.to_latex()\n",
        "pd.DataFrame._repr_latex_ = _repr_latex_\n",
        "#Only used once\n",
        "markers = it.cycle(['+','^','o','_','*','d','x','s'])\n",
        "#handy helper for displaying stuff\n",
        "from IPython.display import Image\n",
        "#\n",
        "#sklearn's packaging is very java-esque. \n",
        "#\n",
        "from sklearn import(cluster,\n",
        "                    datasets,\n",
        "                    decomposition,\n",
        "                    discriminant_analysis,\n",
        "                    dummy,\n",
        "                    ensemble,\n",
        "                    feature_selection as ftr_sel,\n",
        "                    linear_model,\n",
        "                    metrics,\n",
        "                    model_selection as skms,\n",
        "                    multiclass as skmulti,\n",
        "                    naive_bayes,\n",
        "                    neighbors,\n",
        "                    pipeline,\n",
        "                    preprocessing as skpre,\n",
        "                    svm,\n",
        "                    tree)\n",
        "#the punch line is to predict for a large grid of data points\n",
        "#http://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html\n",
        "######################################################################################\n",
        "def plot_boundary(ax, data, tgt, model, dims, grid_step= .01):\n",
        "    #grab a 2D view of the data and get limits\n",
        "    twoD = data[:, list(dims)]\n",
        "    min_x1, min_x2 = np.min(twoD, axis=0) + 2*grid_step\n",
        "    max_x1, max_x2 = np.max(twoD, axis=0) - grid_step\n",
        "    #make a grid of points and predicts at them\n",
        "    xs, ys = np.mgrid[min_x1:max_x1:grid_step,\n",
        "                      min_x2:max_x2:grid_step]\n",
        "    grid_points = np.c_[xs.ravel(),ys.ravel()]\n",
        "    #warning: non-cv fit\n",
        "    preds = model.fit(twoD, tgt).predict(grid_points).reshape(xs.shape)\n",
        "    #plot the predictions at the grid points\n",
        "    ax.pcolormesh(xs,ys,preds,cmap=plt.cm.coolwarm)\n",
        "    ax.set_xlim(min_x1,max_x1)#-grid_step\n",
        "    ax.set_ylim(min_x2,max_x2)#-grid_step\n",
        "######################################################################################\n",
        "def plot_separator(model,xs,ys,label='',ax=None):\n",
        "    '''xs, ys are 1-D b/c contour and decision_function\n",
        "    use incompatible packaging...'''\n",
        "    if ax is None:\n",
        "        ax = plt.gca()\n",
        "        xy = np_cartesian_product(xs,ys)\n",
        "        z_shape = (xs.size,ys.size)# using .size since 1-D\n",
        "        zs = model.decision_function(xy).reshape(z_shape)\n",
        "        contours = ax.contour(xs,ys,zs,\n",
        "                              colors='k', levels=[0],\n",
        "                              linestyles=['-'])\n",
        "        fmt = {contours.levels[0]:label}\n",
        "        labels = ax.clabel(contours, fmt=fmt, inline_spacing=10)\n",
        "        [l.set_rotation(-90) for l in labels]\n",
        "######################################################################################        \n",
        "def high_school_style(ax):\n",
        "    'helper to define an axis to look like a typical school plot'\n",
        "    ax.spines['left'].set_position(('data'),0.0)\n",
        "    ax.spines['bottom'].set_position(('data'),0.0)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    def make_ticks(lims):\n",
        "        lwr,upr = sorted(lims)\n",
        "        lwr = np.round(lwr).astype('int')\n",
        "        upr = np.round(upr).astype('int')\n",
        "        if lwr * upr < 0:\n",
        "            return list(range(lwr,0)) + list(range(1,upr+1))\n",
        "        else:\n",
        "            return list(range(lwr,upr+1))\n",
        "        import matplotlib.ticker as ticker\n",
        "        xticks = make_ticks(ax.get_xlim())\n",
        "        yticks = make_ticks(ax.get_ylim())\n",
        "        ax.xaxis.set_major_locator(ticker.FixedLocator(xticks))\n",
        "        ax.yaxis.set_major_locator(ticker.FixedLocator(yticks))\n",
        "\n",
        "        ax.set_aspect('equal')\n",
        "######################################################################################        \n",
        "def get_model_name(model):\n",
        "    return str(model.__class__).split('.')[-1][:-2]\n",
        "######################################################################################\n",
        "def rdot(w,x):\n",
        "    return np.dot(x,w)\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "class DLDA(BaseEstimator, ClassifierMixin):\n",
        "    def __int__(self):\n",
        "        pass\n",
        "    def fit(self,train_ftrs, train_tgts):\n",
        "        self.unig_tgts = np.unique(train_tgts)\n",
        "        self.means, self.priors = {}, {}\n",
        "        self.var = train_ftrs.var(axis=0)\n",
        "        for tgt in self.unig_tgts:\n",
        "            cases = train_ftrs[train_tgts==tgt]\n",
        "            self.means[tgt] = cases.mean(axis=0)\n",
        "            self.priors[tgt] = len(cases) / len(train_ftrs)\n",
        "        return self\n",
        "    def predict(self,test_ftrs):\n",
        "        disc = np.empty((test_ftrs.shape[0],\n",
        "                         self.unig_tgts.shape[0]))\n",
        "        for tgt in self.unig_tgts:\n",
        "            mahalanobis_dists = ((test_ftrs - self.means[tgt])**2/self.var)\n",
        "            disc[:,tgt] = (-np.sum(mahalanobis_dists, axis=1) +\n",
        "                           2*np.log(self.priors[tgt]))\n",
        "        return np.argmax(disc,axis=1)\n",
        "   ######################################################################################   \n",
        "    def plot_lines_and_projections(axes,lines,points,xs):\n",
        "        data_xs, data_ys = points[:,0], points[:,1]\n",
        "        mean = np.mean(points,axis=0,keepdims = True)\n",
        "        centered_data = points - mean\n",
        "        for (m,b) , ax in zip(lines,axes):\n",
        "            mb_line = m*xs + b\n",
        "            v_line = np.array([[1,1/m if m else 0]])\n",
        "            ax.plot(data_xs,data_ys,'r.')\n",
        "            ax.plot(xs,mb_line,'y')\n",
        "            ax.plot(*mean.T, 'ko')\n",
        "            y_lengths = centered_data.dot(v_line.T)/v_line.dot(v_line.T)\n",
        "            projs = y_lengths.dot(v_line)\n",
        "            final = projs + mean\n",
        "            ax.plot(*final.T,'b.')\n",
        "            from matplotlib import collections as mc\n",
        "            proj_lines = mc.LineCollection(zip(points,final))\n",
        "            ax.add_collection(proj_lines)\n",
        "            hypots = zip(points,np.broadcast_to(mean,points.shape))\n",
        "            mean_lines = mc.LineCollection(hypots,linestyles = 'dashed')\n",
        "            ax.add_collection(mean_lines)\n",
        "######################################################################################\n",
        "    def sane_quiver(vs, ax=None, colors=None, origin=(0,0)):\n",
        "        '''plot row vectors from origin'''\n",
        "        vs = np.arrange(vs)\n",
        "        assert vs.ndim ==2 and vs.shape[1] ==2 \n",
        "        n = vs.shape[0]\n",
        "        if not ax: ax = plt.gca()\n",
        "        orig_x, orig_y = origin\n",
        "        xs = vs.T[0]\n",
        "        ys = vs.T[1]\n",
        "        props = {\"angles\":'xy',\"scale\":1,\"scale_units\": 'xy' }\n",
        "        ax.quiver(orig_x,orig_y,xs,ys,color=colors,**props)\n",
        "        ax.set_aspect('equal')\n",
        "        _min,_max = min(vs.min(),0)-1, max(0,vs.max())+1\n",
        "        ax.set_xlim(_min,_max)\n",
        "        ax.set_ylim(_min,_max)\n",
        "######################################################################################    \n",
        "    def reweight(examples, weights):\n",
        "        from math import gcd\n",
        "        from functools import reduce\n",
        "        min_wgt = min(weights)\n",
        "        min_replicate = 1/min_wgt\n",
        "        counts = (min_replicate * weights * 100).astype(np.int64)\n",
        "        our_gcd = reduce(gcd,counts)\n",
        "        counts = counts//our_gcd\n",
        "        return np.repeat(examples, counts,axis=0)\n",
        "######################################################################################      \n",
        "    def enumerate_outer(outer_seq):\n",
        "        return np.repeat(*zip(*enumerate(map(len,outer_seq))))\n",
        "######################################################################################    \n",
        "    def np_array_fromiter(itr,shape,dtype=np.float64):\n",
        "        arr = np.empty(shape,dtype=dtype)\n",
        "        for idx,itm in enumerate(itr):\n",
        "            arr[idx] = itm\n",
        "        return arr\n",
        "######################################################################################      \n",
        "    def np_cartesian_product(*arrays):\n",
        "        ndim = len(arrays)\n",
        "        return np.stack(np.meshgrid(*arrays), axis=-1).reshape(-1,ndim)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    }
  ]
}